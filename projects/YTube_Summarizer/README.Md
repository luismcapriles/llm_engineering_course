# YouTube Video Summarizer  

## Overview  
This project provides an application that extracts audio from YouTube videos, transcribes the speech, and generates a summarized text version. It integrates **Whisper-1** for speech-to-text transcription and **Meta-Llama-3.1-8B-8192** for summarization. The implementation is optimized for **long videos** by handling chunked audio processing.  

## Features  
‚úÖ Extracts audio from YouTube videos  
‚úÖ Supports **long videos** (handles >30 minutes with chunking)  
‚úÖ Uses **Whisper-large-v3-turbo** for transcription  
‚úÖ Summarizes transcriptions using **Llama3-8B-8192** via Groq API  
‚úÖ Integrated with **Gradio** for an easy-to-use web interface  

## Installation  
1. **Clone the repository**  
   ```bash
   git clone https://github.com/luismcapriles/YTube_Summarizer.git
   ```
2. **Install dependencies**  
   ```bash
   pip install -q requests torch bitsandbytes transformers accelerate gradio sentencepiece yt-dlp datasets[audio] pydub
   ```
3. **Set up API keys**  
   - Create a `.env` file and add: (recommended) 
     ```
     HF_TOKEN=your_huggingface_token
     GROQ_API_KEY=your_groq_api_key
     ```
   - Or set them in the code:  
     ```bash
     HF_TOKEN=your_huggingface_token
     GROQ_API_KEY=your_groq_api_key
     ```

## Usage  
Run the application in Jupyter lab, an automatic Gradio GUI will open in browser  

## How It Works  
1Ô∏è‚É£ **Extracts audio** from the provided YouTube URL using `yt-dlp`.  
2Ô∏è‚É£ **Splits audio** into chunks (for long videos >10 minutes).  
3Ô∏è‚É£ **Transcribes each chunk** using `Whisper-large-v3-turbo`.  
4Ô∏è‚É£ **Summarizes** the full transcription using **Groq‚Äôs Llama3 model**.  
5Ô∏è‚É£ **Displays the summary** in a Gradio web interface.  

## Dependencies  
- `transformers` (for ASR and LLM models)  
- `yt-dlp` (for audio extraction)  
- `pydub` (for audio chunking)  
- `requests` (for API calls)  
- `gradio` (for UI)  

## Limitations  
- **Free Groq API tier** has a rate limit (longer videos may require paid access).  
- **LLM token limit** can restrict large transcriptions.  
- **Slow inference** on CPUs‚Äî**GPU recommended** for local execution.  

## Future Improvements  
üöÄ Optimize text chunk merging for longer video summaries 35+min  


üí° **Contributions welcome!** Feel free to suggest improvements.  
