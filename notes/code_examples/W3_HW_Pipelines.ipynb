{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955f351-44b1-4638-871e-9d95a5c4f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09b900-0b12-4e82-820e-362eb6e930a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b572701-d369-4a8c-b973-3e092c623e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "#from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "from transformers import pipeline\n",
    "from diffusers import DiffusionPipeline\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2968ece6-33f0-4ed7-a942-c7e53642eabc",
   "metadata": {},
   "source": [
    "# Sign in to Hugging Face\n",
    "\n",
    "1. If you haven't already done so, create a free HuggingFace account at https://huggingface.co and navigate to Settings, then Create a new API token, giving yourself write permissions\n",
    "\n",
    "2. Press the \"key\" icon on the side panel to the left, and add a new secret:\n",
    "`HF_TOKEN = your_token`\n",
    "\n",
    "3. Execute the cell below to log in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c7782-22b8-40ac-940a-f4aa04e92401",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.getenv('HF_TOKEN')\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc966eda-8416-4ae0-89e0-1848ae054bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct models\n",
    "\n",
    "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "PHI3 = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "GEMMA2 = \"google/gemma-2-2b-it\"\n",
    "#QWEN2 = \"Qwen/Qwen2-7B-Instruct\" # exercise for you -> too large\n",
    "QWEN2 =\"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MIXTRAL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" # If this doesn't fit it your GPU memory, try others from the hub\n",
    "DEEPSEEKR1 = \"deepseek-ai/DeepSeek-R1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece58a0f-320b-451a-8feb-294850d288e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell a light-hearted joke for a room of Data Scientists\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87df50-63f6-4583-a38f-f0b59c064889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", device=\"cuda\")\n",
    "result = classifier(\"I'm super excited to be on the way to LLM mastery!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8a3ef-c61f-4df5-8704-d96d2972db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True, device=\"cuda\")\n",
    "result = ner(\"Barack Obama was the 44th president of the United States.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee76bca-15a2-42fe-b3ca-4cb515ccd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Answering with Context\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", device=\"cuda\")\n",
    "result = question_answerer(question=\"Who was the 44th president of the United States?\", context=\"Barack Obama was the 44th president of the United States.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52514574-dbbb-49d2-a058-49f379dd796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Summarization\n",
    "\n",
    "summarizer = pipeline(\"summarization\", device=\"cuda\")\n",
    "text = \"\"\"The Hugging Face transformers library is an incredibly versatile and powerful tool for natural language processing (NLP).\n",
    "It allows users to perform a wide range of tasks such as text classification, named entity recognition, and question answering, among others.\n",
    "It's an extremely popular library that's widely used by the open-source data science community.\n",
    "It lowers the barrier to entry into the field by providing Data Scientists with a productive, convenient way to work with transformer models.\n",
    "\"\"\"\n",
    "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d136e-99ff-4cf3-866e-4cbafcf05350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another translation, showing a model being specified\n",
    "# All translation models are here: https://huggingface.co/models?pipeline_tag=translation&sort=trending\n",
    "\n",
    "translator = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\", device=\"cuda\")\n",
    "result = translator(\"The Data Scientists were truly amazed by the power and simplicity of the HuggingFace pipeline API.\")\n",
    "print(result[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0854a-b832-40b3-850f-ff64f9fd199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", device=\"cuda\")\n",
    "result = classifier(\"Hugging Face's Transformers library is amazing!\", candidate_labels=[\"technology\", \"sports\", \"politics\"])\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9eb1a7-a57d-453a-8c31-381025d2e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generation\n",
    "\n",
    "image_gen = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "text = \"A class of Data Scientists learning about AI, in the surreal style of Salvador Dali\"\n",
    "image = image_gen(prompt=text).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ecbbd-e8db-470f-afec-fe3cb56ffb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
